import os
import shutil
import faiss
import pickle
import numpy as np
from openai import OpenAI

# ğŸ” OpenAI API key doÄŸrudan burada
client = OpenAI(api_key="")

# ğŸ“‚ Dosya yollarÄ±
index_path = "data/embeddings/index.faiss"
texts_path = "data/embeddings/texts.pkl"
new_docs_dir = "data/new_docs"
existing_docs_dir = "data/documents"

# ğŸ§¹ Temizlenecek ifadeler
CLEANUP_PHRASES = [
    "Last updated", "Was this helpful?", "Next", "Previous", "Copy", "Netmera Docs",
    "BEGINNER'S GUIDE TO NETMERA", "âŒ˜", "K"
]

# ğŸ”„ FAISS index ve metadata yÃ¼kle
index = faiss.read_index(index_path)
with open(texts_path, "rb") as f:
    metadata = pickle.load(f)

# ğŸ§  Eski format dÃ¶nÃ¼ÅŸtÃ¼r
if isinstance(metadata[0], str):
    metadata = [{"text": para, "source": f"legacy_{i}"} for i, para in enumerate(metadata)]

# âœ… Zaten iÅŸlenmiÅŸ dosyalar
processed_files = set(item["source"] for item in metadata)
existing_filenames = set(f.replace(".txt", "") for f in os.listdir(existing_docs_dir) if f.endswith(".txt"))

# ğŸ“‘ Embedlenecek dosyalar
new_files = [
    f for f in os.listdir(new_docs_dir)
    if f.endswith(".txt") and f.replace(".txt", "") not in processed_files and f.replace(".txt", "") not in existing_filenames
]

if not new_files:
    print("ğŸš« Yeni dosya bulunamadÄ± veya zaten iÅŸlenmiÅŸ.")
    exit()

# ğŸ“¥ Ä°ÅŸleme baÅŸla
for filename in new_files:
    filepath = os.path.join(new_docs_dir, filename)
    with open(filepath, "r", encoding="utf-8") as f:
        content = f.read()

    # âœ‚ï¸ Gereksiz kelimeleri temizle
    for phrase in CLEANUP_PHRASES:
        content = content.replace(phrase, "")

    # ğŸ”„ BoÅŸ olmayan tÃ¼m paragraflarÄ± al (uzunluk filtresi yok)
    paragraphs = [p.strip() for p in content.split("\n") if p.strip()]

    for para in paragraphs:
        response = client.embeddings.create(
            input=[para],
            model="text-embedding-ada-002"
        )
        embedding = np.array(response.data[0].embedding, dtype=np.float32).reshape(1, -1)

        index.add(embedding)
        metadata.append({
            "text": para,
            "source": filename.replace(".txt", "")
        })

    # âœ… DosyayÄ± taÅŸÄ±
    shutil.move(filepath, os.path.join(existing_docs_dir, filename))

# ğŸ’¾ Kaydet
faiss.write_index(index, index_path)
with open(texts_path, "wb") as f:
    pickle.dump(metadata, f)

print(f"âœ… Yeni dosyalar iÅŸlendi ve taÅŸÄ±ndÄ±: {len(new_files)} adet")